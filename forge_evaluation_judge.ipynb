{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "from set_env import set_env\n",
    "import nest_asyncio\n",
    "from evalforge.evalforge import EvalForge, convert_datapoint_to_example\n",
    "from evalforge.combined_scorer import predict_passthrough\n",
    "import asyncio\n",
    "from evalforge.evalforge_alignment import calculate_alignment_metrics, format_alignment_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env set\n"
     ]
    }
   ],
   "source": [
    "set_env(\"OPENAI_API_KEY\")\n",
    "set_env(\"WANDB_API_KEY\")\n",
    "print(\"Env set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import IPython\n",
    "    in_jupyter = True\n",
    "except ImportError:\n",
    "    in_jupyter = False\n",
    "if in_jupyter:\n",
    "    nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: a-sh0ts.\n",
      "View Weave data at https://wandb.ai/a-sh0ts/evalgen_test_379476/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.trace.weave_client.WeaveClient at 0x147cd9250>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "weave.init(f\"evalgen_test_{random.randint(0, 1000000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TASK = \"medical\"\n",
    "if TEST_TASK == \"medical\":\n",
    "    all_data = weave.ref(\"weave:///a-sh0ts/medical_data_results/object/medical_data_annotations:7GcCtWgyPTWtKY48Z7v5VxwCNZXTTTpSMbmubAbyHT8\").get()\n",
    "    data = random.sample(all_data, 10)\n",
    "elif TEST_TASK == \"product\":\n",
    "    pass\n",
    "else:\n",
    "    all_data = data = [\n",
    "        ({\"text\": \"Summarize the impact of climate change on polar bears.\"}, {\"text\": \"Climate change is reducing sea ice, which polar bears rely on for hunting seals.\"}, 1, \"Accurate and relevant.\"),\n",
    "        ({\"text\": \"Explain the process of photosynthesis.\"}, {\"text\": \"Photosynthesis is the process by which plants use sunlight to synthesize foods from carbon dioxide and water.\"}, 1, \"Correct and detailed.\"),\n",
    "        ({\"text\": \"What are the main causes of the American Civil War?\"}, {\"text\": \"The main causes were slavery, states' rights, and economic differences.\"}, 1, \"Concise and accurate.\"),\n",
    "        ({\"text\": \"Describe the symptoms of COVID-19.\"}, {\"text\": \"COVID-19 is caused by a virus that originated in bats.\"}, 0, \"Irrelevant and incorrect.\"),\n",
    "        ({\"text\": \"What is the significance of the Magna Carta?\"}, {\"text\": \"The Magna Carta was a document that limited the power of the king and established certain legal rights.\"}, 1, \"Historically accurate and relevant.\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/a-sh0ts/evalgen_test_379476/r/call/01921103-380e-7920-9c5d-07cb829eb840\n"
     ]
    }
   ],
   "source": [
    "forger = EvalForge()\n",
    "\n",
    "results = await forger.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forged_judge = results[\"forged_judges\"][\"judge\"]\n",
    "forged_judges_metrics = results[\"forged_judges\"][\"alignment_metrics\"]\n",
    "forged_judges_assertion_results = results[\"forged_judges\"][\"assertion_results\"]\n",
    "forged_judges_summary = results[\"forged_judges\"][\"summary\"]\n",
    "\n",
    "raw_judges = results[\"raw_judges\"][\"judge\"]\n",
    "raw_judges_metrics = results[\"raw_judges\"][\"alignment_metrics\"]\n",
    "raw_judges_assertion_results = results[\"raw_judges\"][\"assertion_results\"]\n",
    "raw_judges_summary = results[\"raw_judges\"][\"summary\"]\n",
    "\n",
    "annotation_examples = results[\"annotation_examples\"]\n",
    "finalized_task_description = results[\"finalized_task_description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Adherence to format and completeness     | **OVERALL**                             |           | 0.54     |\n",
      "|                                         | evaluate_structure_and_completeness      | llm       | 0.29     |\n",
      "|                                         | test_adheres_to_bullet_point_format      | code      | 0.00     |\n",
      "| Exclusion of personal identifiable infor | **OVERALL**                             |           | 0.71     |\n",
      "|                                         | evaluate_exclusion_of_pii                | llm       | 0.71     |\n",
      "| Accuracy and Relevance of Transformed No | **OVERALL**                             |           | 0.54     |\n",
      "|                                         | relevance_of_transformed_notes           | llm       | 0.29     |\n",
      "|                                         | test_accuracy_of_medical_details         | code      | 0.00     |\n",
      "\n",
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Adherence to format and completeness     | **OVERALL**                             |           | 0.46     |\n",
      "|                                         | evaluate_structure_and_completeness      | llm       | 0.29     |\n",
      "|                                         | test_adheres_to_bullet_point_format      | code      | 0.00     |\n",
      "|                                         | test_all_mandatory_fields_present        | code      | 0.00     |\n",
      "| Exclusion of personal identifiable infor | **OVERALL**                             |           | 0.52     |\n",
      "|                                         | evaluate_exclusion_of_pii                | llm       | 0.71     |\n",
      "|                                         | test_no_pii_in_output                    | code      | 0.00     |\n",
      "| Accuracy and Relevance of Transformed No | **OVERALL**                             |           | 0.46     |\n",
      "|                                         | relevance_of_transformed_notes           | llm       | 0.29     |\n",
      "|                                         | test_accuracy_of_medical_details         | code      | 0.00     |\n",
      "|                                         | test_exclusion_of_pii                    | code      | 0.00     |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(forged_judges_summary)\n",
    "print(raw_judges_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The task requires transforming detailed medical dialogues between a doctor and a patient into structured medical notes in a standardized bullet-point list format. The dialogues provide comprehensive information on the patient's medical history, current symptoms, examination findings, familial history, allergies, medications, and future healthcare plans. The output should be a concise, structured list containing the mandatory fields: Chief complaint, History of present illness, Physical examination findings, Symptoms, New medications with dosages, and Follow-up instructions. Missing data should be marked as 'N/A'. The process demands the accurate extraction and summary of relevant medical information while strictly omitting any personally identifiable information (PII) to ensure privacy, substituting terms like 'the patient' for specific identifiers. Notes should maintain consistent punctuation and formatting, with new medications distinctly separated from existing ones. Evaluation focuses on accuracy, completeness, adherence to structure, exclusion of PII, consistent punctuation, and correct labeling of missing data. This task aims to produce anonymized medical notes that support healthcare delivery without compromising patient confidentiality, adhering to relevance, conciseness, and a 150-word limit for summaries if necessary.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalized_task_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "async def run_assertions_and_calculate_metrics(forger, judge, data, task_description):\n",
    "    all_annotation_examples = convert_datapoint_to_example(task_description, data)\n",
    "    all_data_forged_judge_assertion_results = await forger.run_assertions(judge, all_annotation_examples)\n",
    "    all_data_metrics = calculate_alignment_metrics(all_data_forged_judge_assertion_results)\n",
    "    all_data_metrics_str = format_alignment_metrics(all_data_metrics)\n",
    "    return all_data_metrics_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/a-sh0ts/evalgen_test_379476/r/call/01921104-8ce1-7962-a215-02563ec93d50\n",
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Exclusion of personal identifiable infor | **OVERALL**                             |           | 0.50     |\n",
      "|                                         | evaluate_exclusion_of_pii                | llm       | 0.50     |\n",
      "| Adherence to format and completeness     | **OVERALL**                             |           | 0.50     |\n",
      "|                                         | evaluate_structure_and_completeness      | llm       | 0.00     |\n",
      "|                                         | test_adheres_to_bullet_point_format      | code      | 0.00     |\n",
      "| Accuracy and Relevance of Transformed No | **OVERALL**                             |           | 0.54     |\n",
      "|                                         | relevance_of_transformed_notes           | llm       | 0.29     |\n",
      "|                                         | test_accuracy_of_medical_details         | code      | 0.00     |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(await run_assertions_and_calculate_metrics(forger, forged_judge, data, finalized_task_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_annotation_examples = convert_datapoint_to_example(finalized_task_description, all_data)\n",
    "# evaluation = weave.Evaluation(\n",
    "#     scorers=[forged_judge],\n",
    "#     dataset=all_annotation_examples,\n",
    "# )\n",
    "\n",
    "\n",
    "# final_judge_results = asyncio.run(evaluation.evaluate(predict_passthrough))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Published to https://wandb.ai/a-sh0ts/evalgen_test_379476/weave/objects/final_judge/versions/SZSv6IC9FAdCL6wY6ZmRVoQcpWEyd917Y7KubRFNHWA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectRef(entity='a-sh0ts', project='evalgen_test_379476', name='final_judge', digest='SZSv6IC9FAdCL6wY6ZmRVoQcpWEyd917Y7KubRFNHWA', extra=())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave.publish(forged_judge, name=\"final_judge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forged_judge.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
