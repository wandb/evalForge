{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "from set_env import set_env\n",
    "import nest_asyncio\n",
    "from evalforge.evalforge import EvalForge, convert_datapoint_to_example\n",
    "from evalforge.evalforge_alignment import calculate_alignment_metrics, format_alignment_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env set\n"
     ]
    }
   ],
   "source": [
    "set_env(\"OPENAI_API_KEY\")\n",
    "set_env(\"WANDB_API_KEY\")\n",
    "print(\"Env set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import IPython\n",
    "    in_jupyter = True\n",
    "except ImportError:\n",
    "    in_jupyter = False\n",
    "if in_jupyter:\n",
    "    nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: a-sh0ts.\n",
      "View Weave data at https://wandb.ai/a-sh0ts/evalgen_test_514403/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.trace.weave_client.WeaveClient at 0x15d783bc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "weave.init(f\"evalforge_test_{random.randint(0, 1000000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TASK = \"medical\"\n",
    "if TEST_TASK == \"medical\":\n",
    "    all_data = weave.ref(\"weave:///a-sh0ts/medical_data_results/object/medical_data_annotations:7GcCtWgyPTWtKY48Z7v5VxwCNZXTTTpSMbmubAbyHT8\").get()\n",
    "    data = random.sample(all_data, 10)\n",
    "elif TEST_TASK == \"product\":\n",
    "    pass\n",
    "else:\n",
    "    all_data = data = [\n",
    "        ({\"text\": \"Summarize the impact of climate change on polar bears.\"}, {\"text\": \"Climate change is reducing sea ice, which polar bears rely on for hunting seals.\"}, 1, \"Accurate and relevant.\"),\n",
    "        ({\"text\": \"Explain the process of photosynthesis.\"}, {\"text\": \"Photosynthesis is the process by which plants use sunlight to synthesize foods from carbon dioxide and water.\"}, 1, \"Correct and detailed.\"),\n",
    "        ({\"text\": \"What are the main causes of the American Civil War?\"}, {\"text\": \"The main causes were slavery, states' rights, and economic differences.\"}, 1, \"Concise and accurate.\"),\n",
    "        ({\"text\": \"Describe the symptoms of COVID-19.\"}, {\"text\": \"COVID-19 is caused by a virus that originated in bats.\"}, 0, \"Irrelevant and incorrect.\"),\n",
    "        ({\"text\": \"What is the significance of the Magna Carta?\"}, {\"text\": \"The Magna Carta was a document that limited the power of the king and established certain legal rights.\"}, 1, \"Historically accurate and relevant.\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/a-sh0ts/evalgen_test_514403/r/call/01921118-16d4-70d0-86c4-6bf8e5ff172d\n"
     ]
    }
   ],
   "source": [
    "forger = EvalForge()\n",
    "\n",
    "results = await forger.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forged_judge = results[\"forged_judges\"][\"judge\"]\n",
    "forged_judges_metrics = results[\"forged_judges\"][\"alignment_metrics\"]\n",
    "forged_judges_assertion_results = results[\"forged_judges\"][\"assertion_results\"]\n",
    "forged_judges_summary = results[\"forged_judges\"][\"summary\"]\n",
    "\n",
    "raw_judges = results[\"raw_judges\"][\"judge\"]\n",
    "raw_judges_metrics = results[\"raw_judges\"][\"alignment_metrics\"]\n",
    "raw_judges_assertion_results = results[\"raw_judges\"][\"assertion_results\"]\n",
    "raw_judges_summary = results[\"raw_judges\"][\"summary\"]\n",
    "\n",
    "annotation_examples = results[\"annotation_examples\"]\n",
    "finalized_task_description = results[\"finalized_task_description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Accuracy and Completeness                | **OVERALL**                             |           | 0.86     |\n",
      "|                                         | check_accuracy_and_completeness          | llm       | 0.86     |\n",
      "| Clarity and Conciseness                  | **OVERALL**                             |           | 0.00     |\n",
      "|                                         | evaluate_organization_and_conciseness    | llm       | 0.00     |\n",
      "| Adherence to Structure and Format        | **OVERALL**                             |           | 0.60     |\n",
      "|                                         | structure_and_format_llm_check           | llm       | 0.60     |\n",
      "\n",
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Accuracy and Completeness                | **OVERALL**                             |           | 0.40     |\n",
      "|                                         | check_accuracy_and_completeness          | llm       | 0.86     |\n",
      "|                                         | test_important_clinical_data_inclusion   | code      | 0.00     |\n",
      "|                                         | test_no_pii_in_output                    | code      | 0.00     |\n",
      "| Clarity and Conciseness                  | **OVERALL**                             |           | 0.00     |\n",
      "|                                         | evaluate_organization_and_conciseness    | llm       | 0.00     |\n",
      "|                                         | test_clarity_of_history_section          | code      | 0.00     |\n",
      "|                                         | test_exclusion_of_pii                    | code      | 0.00     |\n",
      "| Adherence to Structure and Format        | **OVERALL**                             |           | 0.38     |\n",
      "|                                         | structure_and_format_llm_check           | llm       | 0.60     |\n",
      "|                                         | test_adherence_to_bullet_point_format    | code      | 0.00     |\n",
      "|                                         | test_appropriate_nda_usage               | code      | 0.00     |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(forged_judges_summary)\n",
    "print(raw_judges_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The task involves transforming dialogues between doctors and patients and accompanying medical notes into precise and structured medical summaries. The input consists of textual transcriptions detailing both the dialogues and comprehensive medical notes. The aim is to extract and systematically organize essential clinical data into categorized bullet points such as chief complaint, history of present illness, physical examination findings, symptoms, medication instructions, and follow-up guidelines. Summaries must exclude all personally identifiable information (PII), including names, ages, genders, ensuring confidentiality by referring to 'the patient.' Each section must be comprehensive and indicate 'N/A' if specific information is lacking while maintaining brevity within a 150-word limit. A clear distinction between newly prescribed medications and existing ones, with detailed dosage information or 'N/A' for unchanged dosages, is essential. The evaluation criteria focus on accuracy, completeness, clarity, organization, and privacy adherence.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalized_task_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "async def run_assertions_and_calculate_metrics(forger, judge, data, task_description):\n",
    "    all_annotation_examples = convert_datapoint_to_example(task_description, data)\n",
    "    all_data_forged_judge_assertion_results = await forger.run_assertions(judge, all_annotation_examples)\n",
    "    all_data_metrics = calculate_alignment_metrics(all_data_forged_judge_assertion_results)\n",
    "    all_data_metrics_str = format_alignment_metrics(all_data_metrics)\n",
    "    return all_data_metrics_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/a-sh0ts/evalgen_test_514403/r/call/01921119-3799-7b41-899a-8eaa2c63aa2e\n",
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Accuracy and Completeness                | **OVERALL**                             |           | 0.79     |\n",
      "|                                         | check_accuracy_and_completeness          | llm       | 0.79     |\n",
      "| Adherence to Structure and Format        | **OVERALL**                             |           | 0.71     |\n",
      "|                                         | structure_and_format_llm_check           | llm       | 0.71     |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(await run_assertions_and_calculate_metrics(forger, forged_judge, data, finalized_task_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_annotation_examples = convert_datapoint_to_example(finalized_task_description, all_data)\n",
    "# evaluation = weave.Evaluation(\n",
    "#     scorers=[forged_judge],\n",
    "#     dataset=all_annotation_examples,\n",
    "# )\n",
    "\n",
    "\n",
    "# final_judge_results = asyncio.run(evaluation.evaluate(predict_passthrough))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Published to https://wandb.ai/a-sh0ts/evalgen_test_514403/weave/objects/final_judge/versions/N7ZhN6Al1f2oN0yXDOEx0kspbMVMkkpIjxSjKyKK4z4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectRef(entity='a-sh0ts', project='evalgen_test_514403', name='final_judge', digest='N7ZhN6Al1f2oN0yXDOEx0kspbMVMkkpIjxSjKyKK4z4', extra=())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave.publish(forged_judge, name=\"final_judge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "forged_judge.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
