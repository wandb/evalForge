{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Literal, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import weave\n",
    "import instructor\n",
    "from set_env import set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_env(\"OPENAI_API_KEY\")\n",
    "set_env(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.init(\"medical_data_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "medical_task = \"\"\"\n",
    "You are extracting insights from some medical records.\n",
    "The records contain a medical note and a\n",
    "dialogue between a doctor and a patient. You need\n",
    "to extract values for the following: Chief\n",
    "complaint, History of present illness, Physical\n",
    "examination, symptoms experienced by the patient,\n",
    "New medications prescribed or changed, including\n",
    "dosages (N/A if not provided), and Follow-up\n",
    "instructions (N/A if not provided). Your answer\n",
    "should not include any personal identifiable\n",
    "information (PII) such as name, age, gender, or\n",
    "ID. Use \"the patient\" instead of their name, for\n",
    "example. Return your answer as a bullet list,\n",
    "where each bullet is formatted like •chief\n",
    "complaint: xx. If there is no value for the key,\n",
    "the value should be N/A. Keep your response\n",
    "around 150 words (you may have to summarize some\n",
    "extracted values to stay within the word limit).\n",
    "{transcript}\n",
    "\"\"\"\n",
    "\n",
    "medical_system_prompt = \"\"\"\n",
    "You are a medical data extraction AI assistant. Your task is to accurately extract and summarize key medical information from patient records, adhering strictly to privacy guidelines and formatting instructions provided in the user's prompt. Focus on relevance and conciseness while ensuring all required fields are addressed.\n",
    "\"\"\"\n",
    "\n",
    "medical_dataset_url = \"https://raw.githubusercontent.com/wyim/aci-bench/main/data/challenge_data/train.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_medical_data(url: str, num_samples: int = N_SAMPLES) -> List[Dict]:\n",
    "    df = pd.read_csv(url)\n",
    "    print(df.shape)\n",
    "    samples = df.sample(n=num_samples, random_state=42)\n",
    "    return samples.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = load_medical_data(medical_dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_transcript(record):\n",
    "    dialogue = record['dialogue'].replace('\\n', ' ')\n",
    "    note = record['note'].replace('\\n', ' ')\n",
    "    transcript = f\"Dialogue: {dialogue}\\n\\nMedical Note: {note}\"\n",
    "    return transcript\n",
    "\n",
    "@weave.op()\n",
    "def process_medical_record(record: Dict) -> Dict:\n",
    "    transcript = format_transcript(record)\n",
    "    prompt = medical_task.format(transcript=transcript)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": medical_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    extracted_info = response.choices[0].message.content\n",
    "    \n",
    "    return {\n",
    "        \"input\": transcript,\n",
    "        \"output\": extracted_info,\n",
    "    }\n",
    "\n",
    "@weave.op()\n",
    "def generate_medical_data(num_samples: int = N_SAMPLES) -> List[Dict]:\n",
    "    data = load_medical_data(medical_dataset_url, num_samples)\n",
    "    processed_data = []\n",
    "    \n",
    "    for record in data:\n",
    "        processed_record = process_medical_record(record)\n",
    "        processed_data.append(processed_record)\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_medical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.patch(openai.OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotationResult(BaseModel):\n",
    "    annotation: Literal[0, 1] = Field(\n",
    "        description=\"Binary score: 1 if the extraction meets all criteria, 0 if it fails on any\"\n",
    "    )\n",
    "    note: str = Field(\n",
    "        description=\"Brief explanation of the annotation decision, highlighting any issues or exemplary aspects\"\n",
    "    )\n",
    "\n",
    "annotation_prompt = \"\"\"\n",
    "    Review the following medical data extraction task results:\n",
    "\n",
    "    Task System Prompt:\n",
    "    {medical_system_prompt}\n",
    "\n",
    "    Task:\n",
    "    {medical_task}\n",
    "\n",
    "    Input:\n",
    "    {input_text}\n",
    "\n",
    "    Output:\n",
    "    {output_text}\n",
    "\n",
    "    Evaluate the extraction based on these criteria:\n",
    "    1. Completeness: All required fields addressed (Chief complaint, History of present illness, Physical examination, Symptoms, New medications with dosages, Follow-up instructions)\n",
    "    2. Accuracy: Information correctly extracted from input\n",
    "    3. Format: Proper bullet list format used (•key: value)\n",
    "    4. Privacy: No personal identifiable information (PII) included\n",
    "    5. Conciseness: ~150 words, key information summarized\n",
    "    6. Use of \"N/A\" for missing information\n",
    "\n",
    "    Provide:\n",
    "    1. Annotation: 1 if the extraction meets all criteria, 0 if it fails on any\n",
    "    2. Note: Brief explanation of your decision, highlighting any issues or exemplary aspects\n",
    "\"\"\"\n",
    "\n",
    "annotation_system_prompt = \"\"\"\n",
    "You are an AI assistant tasked with evaluating medical data extraction results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def process_annotation(input_text: str, output_text: str) -> AnnotationResult:\n",
    "    prompt = annotation_prompt.format(medical_system_prompt=medical_system_prompt, medical_task=medical_task, input_text=input_text, output_text=output_text)\n",
    "    \n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": annotation_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=AnnotationResult\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPoint = Tuple[dict, dict, Literal[0, 1], str, Optional[str], Optional[str]]\n",
    "\n",
    "@weave.op()\n",
    "def generate_annotations(results: List[Dict]) -> List[DataPoint]:\n",
    "    annotations = []\n",
    "    \n",
    "    for result in results:\n",
    "        input_text = result[\"input\"]\n",
    "        output_text = result[\"output\"]\n",
    "        annotation_result = process_annotation(input_text, output_text)\n",
    "\n",
    "        combined_task_description = f\"System Prompt: {medical_system_prompt}\\n\\nTask: {medical_task}\"\n",
    "        \n",
    "        data_point: DataPoint = (\n",
    "            {\"input\": input_text},  # input\n",
    "            {\"output\": output_text},  # output\n",
    "            annotation_result.annotation,  # annotation (1 for correct, 0 for incorrect)\n",
    "            annotation_result.note,  # note\n",
    "            combined_task_description,  # human_description_for_task_or_judge\n",
    "            \"word count, presence of the six targeted keys, and absence of PII, with the first two implemented via code- based assertions and the last via an LLM evaluator\"  # human_description_for_metric_details\n",
    "        )\n",
    "        \n",
    "        annotations.append(data_point)\n",
    "    \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = generate_annotations(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.publish(annotations, name=\"medical_data_annotations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
