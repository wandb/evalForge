{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "from set_env import set_env\n",
    "import nest_asyncio\n",
    "from evalforge.evalforge import EvalForge, convert_datapoint_to_example\n",
    "from evalforge.combined_scorer import predict_passthrough\n",
    "import asyncio\n",
    "from evalforge.evalforge_alignment import calculate_alignment_metrics, format_alignment_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-19 13:02:15.388\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mset_env.set_env\u001b[0m:\u001b[36mset_env\u001b[0m:\u001b[36m100\u001b[0m - \u001b[33m\u001b[1m\n",
      "        Unable to set WANDB_API_KEY=WANDB_API_KEY,\n",
      "        not in colab or Secrets not set, not kaggle\n",
      "        or Secrets not set, no .env/dotenv/env file\n",
      "        in the current working dir or parent dirs.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading envfile='/Users/anishshah/Documents/Manual Library/GitHub(1)/improve-evals/.env' with dotenv_values(envfile)\n"
     ]
    }
   ],
   "source": [
    "set_env(\"OPENAI_API_KEY\")\n",
    "set_env(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import IPython\n",
    "    in_jupyter = True\n",
    "except ImportError:\n",
    "    in_jupyter = False\n",
    "if in_jupyter:\n",
    "    nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: a-sh0ts.\n",
      "View Weave data at https://wandb.ai/a-sh0ts/evalgen_test_368098/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.weave_client.WeaveClient at 0x175113ec0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "weave.init(f\"evalgen_test_{random.randint(0, 1000000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TASK = \"medical\"\n",
    "if TEST_TASK == \"medical\":\n",
    "    all_data = weave.ref(\"weave:///a-sh0ts/medical_data_results/object/medical_data_annotations:7GcCtWgyPTWtKY48Z7v5VxwCNZXTTTpSMbmubAbyHT8\").get()\n",
    "    data = random.sample(all_data, 10)\n",
    "elif TEST_TASK == \"product\":\n",
    "    pass\n",
    "else:\n",
    "    all_data = data = [\n",
    "        ({\"text\": \"Summarize the impact of climate change on polar bears.\"}, {\"text\": \"Climate change is reducing sea ice, which polar bears rely on for hunting seals.\"}, 1, \"Accurate and relevant.\"),\n",
    "        ({\"text\": \"Explain the process of photosynthesis.\"}, {\"text\": \"Photosynthesis is the process by which plants use sunlight to synthesize foods from carbon dioxide and water.\"}, 1, \"Correct and detailed.\"),\n",
    "        ({\"text\": \"What are the main causes of the American Civil War?\"}, {\"text\": \"The main causes were slavery, states' rights, and economic differences.\"}, 1, \"Concise and accurate.\"),\n",
    "        ({\"text\": \"Describe the symptoms of COVID-19.\"}, {\"text\": \"COVID-19 is caused by a virus that originated in bats.\"}, 0, \"Irrelevant and incorrect.\"),\n",
    "        ({\"text\": \"What is the significance of the Magna Carta?\"}, {\"text\": \"The Magna Carta was a document that limited the power of the king and established certain legal rights.\"}, 1, \"Historically accurate and relevant.\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forger = EvalForge()\n",
    "\n",
    "results = await forger.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forged_judge = results[\"forged_judges\"][\"judge\"]\n",
    "forged_judges_metrics = results[\"forged_judges\"][\"alignment_metrics\"]\n",
    "forged_judges_assertion_results = results[\"forged_judges\"][\"assertion_results\"]\n",
    "forged_judges_summary = results[\"forged_judges\"][\"summary\"]\n",
    "\n",
    "raw_judges = results[\"raw_judges\"][\"judge\"]\n",
    "raw_judges_metrics = results[\"raw_judges\"][\"alignment_metrics\"]\n",
    "raw_judges_assertion_results = results[\"raw_judges\"][\"assertion_results\"]\n",
    "raw_judges_summary = results[\"raw_judges\"][\"summary\"]\n",
    "\n",
    "annotation_examples = results[\"annotation_examples\"]\n",
    "finalized_task_description = results[\"finalized_task_description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Completeness of Information Extraction   | **OVERALL**                             |           | 0.53     |\n",
      "|                                         | evaluate_completeness_of_information_ext | llm       | 0.25     |\n",
      "|                                         | test_all_required_fields_present         | code      | 0.00     |\n",
      "| Privacy Maintenance                      | **OVERALL**                             |           | 0.52     |\n",
      "|                                         | anonymization_of_patient_information     | llm       | 0.52     |\n",
      "| Conciseness and Redundancy Avoidance     | **OVERALL**                             |           | 0.53     |\n",
      "|                                         | conciseness_and_avoidance_of_redundancy  | llm       | 0.25     |\n",
      "|                                         | test_avoid_redudancy_in_summary          | code      | 0.00     |\n",
      "\n",
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Completeness of Information Extraction   | **OVERALL**                             |           | 0.51     |\n",
      "|                                         | evaluate_completeness_of_information_ext | llm       | 0.25     |\n",
      "|                                         | evaluate_privacy_compliance              | llm       | 0.40     |\n",
      "|                                         | test_all_required_fields_present         | code      | 0.00     |\n",
      "| Privacy Maintenance                      | **OVERALL**                             |           | 0.40     |\n",
      "|                                         | no_personally_identifiable_information_p | llm       | 0.38     |\n",
      "|                                         | anonymization_of_patient_information     | llm       | 0.52     |\n",
      "|                                         | test_no_pii_in_output                    | code      | 0.00     |\n",
      "| Conciseness and Redundancy Avoidance     | **OVERALL**                             |           | 0.45     |\n",
      "|                                         | conciseness_and_avoidance_of_redundancy  | llm       | 0.25     |\n",
      "|                                         | test_avoid_redudancy_in_summary          | code      | 0.00     |\n",
      "|                                         | test_concisely_below_word_limit          | code      | 0.00     |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(forged_judges_summary)\n",
    "print(raw_judges_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "async def run_assertions_and_calculate_metrics(forger, judge, data, task_description):\n",
    "    all_annotation_examples = convert_datapoint_to_example(task_description, data)\n",
    "    all_data_forged_judge_assertion_results = await forger.run_assertions(judge, all_annotation_examples)\n",
    "    all_data_metrics = calculate_alignment_metrics(all_data_forged_judge_assertion_results)\n",
    "    all_data_metrics_str = format_alignment_metrics(all_data_metrics)\n",
    "    return all_data_metrics_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Criterion                               | Assertion                               | Type      | Alignment |\n",
      "|-----------------------------------------|-----------------------------------------|-----------|-----------|\n",
      "| Completeness of Information Extraction   | **OVERALL**                             |           | 0.53     |\n",
      "|                                         | evaluate_completeness_of_information_ext | llm       | 0.25     |\n",
      "|                                         | test_all_required_fields_present         | code      | 0.00     |\n",
      "| Conciseness and Redundancy Avoidance     | **OVERALL**                             |           | 0.53     |\n",
      "|                                         | conciseness_and_avoidance_of_redundancy  | llm       | 0.25     |\n",
      "|                                         | test_avoid_redudancy_in_summary          | code      | 0.00     |\n",
      "| Privacy Maintenance                      | **OVERALL**                             |           | 0.31     |\n",
      "|                                         | anonymization_of_patient_information     | llm       | 0.31     |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(await run_assertions_and_calculate_metrics(forger, forged_judge, data, finalized_task_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotation_examples = convert_datapoint_to_example(finalized_task_description, data)\n",
    "evaluation = weave.Evaluation(\n",
    "    scorers=[forged_judge],\n",
    "    dataset=all_annotation_examples,\n",
    ")\n",
    "\n",
    "\n",
    "final_judge_results = asyncio.run(evaluation.evaluate(predict_passthrough))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.publish(forged_judge, name=\"final_judge\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
